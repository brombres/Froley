library Froley

# Generated by Froley. WARNING: WILL BE OVERWRITTEN.

$include "CompileError.rogue"
$include "ScanTable.rogue"
$include "Token.rogue"
$include "TokenType.rogue"

class ScannerCore [abstract]
  DEFINITIONS
    ip_scan_standard_token = 0
    ip_scan_charset = 1
    ip_consume_whitespace = 2
    ip_consume_comment = 3
    ip_scan_optional_plain_id = 4
    ip_scan_tokens_id = 5
    ip_scan_token_name = 6
    ip_scan_token_symbol = 7
    ip_scan_token_attributes = 8
    ip_scan_identifier = 9
    ip_must_scan_attribute_identifier = 10
    ip_scan_integer = 11
    ip_scan_native_literal = 12
    ip_scan_single_quoted_string = 13
    ip_scan_double_quoted_string = 14
    ip_scan_anycase_string = 15
    ip_scan_literal_character = 16

  PROPERTIES
    _filepath     : String
    _scanner      : Rogue::Scanner
    line          = 1
    column        = 1
    position      = 0

    tokens        : Token[]
    buffer        = String()
    output        = String()

    start_ip      = 0
    halt          = false

    _position_stack  = Int[]
    _line_stack      = Int[]
    _column_stack    = Int[]
    _token_pos_stack = Int[]

    # GENERATED PROPERTIES
    ch    : Character
    count : Int
    _scan_pattern_0 = ScanPattern( "[0-9]" )
    _scan_pattern_1 = ScanPattern( "{[a-zA-Z_][a-zA-Z_0-9]*}" )
    _scan_pattern_2 = ScanPattern( "{[a-zA-Z_][a-zA-Z0-9_]*}" )
    _scan_pattern_3 = ScanPattern( "[0-9_]" )
    _scan_table_0 = ScanTable("gQ4AFy0wPTpAQGBCXkR9RilIXUo6TCxOLlBbVj5cPGIhaHtuKHArcj94O3onfC+BCiqBDBMCPjYtOAEAFAACAT0+DQADAAQABQAGAAcACAAJAAoA/wEuVAsAFwFdWgwADwE9YA4AEQE9ZhAA/wE9bBIAFQAWABgBK3YZABoAGwD/AVyBAP8BJ4EE/wEngQgcAB0AHgA=")
    _scan_table_1 = ScanTable("egAEbgpwNHNKdGT/AWEO/wF0Ev8BaRb/AXYa/wFlHv8BVCL/AXkm/wFwKv8BZS7/AXMyAQD/AWE4/wFyPP8Bc0D/AWVE/wFySAIA/wFjTv8BYVL/AW5W/wFuWv8BZV7/AXJiAwD/AW9o/wFrbP8BZXD/AW50/wFzeAQA")
    _scan_table_2 = ScanTable("Ev8ECgpbDF0OLBAAAAEAAgADAA==")
    _scan_table_3 = ScanTable("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")

  METHODS
    method init
      noAction

    method init( file:File )
      init( file.filepath, Rogue::Scanner(file) )

    method init( filepath:String, content:String )
      init( filepath, Rogue::Scanner(content) )

    method init( _filepath, _scanner )
      noAction

    method reset( start_ip=0 )
      if (_scanner) _scanner.reset
      line   = 1
      column = 1
      tokens = null
      buffer.clear
      output.clear
      halt = false
      _position_stack.clear
      _line_stack.clear
      _column_stack.clear
      _token_pos_stack.clear

    method reset( file:File, start_ip=0:Int )
      reset( start_ip )
      init( file )

    method reset( filepath:String, content:String, start_ip=0:Int )
      reset( start_ip )
      init( filepath, content )

    method reset( t:Token, start_ip=0:Int, scan_limit=null:Int? )
      reset( start_ip )
      init( t.filepath, t.source )
      if (scan_limit) _scanner.count = t.position + scan_limit.value
      _scanner.seek( t.position )
      line = t.line
      column = t.column
      position = t.position

    method execute( ip:Int )
      _clear_state
      _execute( ip )

    method tokenize( file:File, line=1, column=1, &ip=null:Int? )->Token[]
      return tokenize( file.filepath, Rogue::Scanner(file) )

    method tokenize( filepath:String, content:String, line=1, column=1, &ip=null:Int? )->Token[]
      return tokenize( filepath, Rogue::Scanner(content).[line=line, column=column] )

    method tokenize( _filepath, _scanner, line=1, column=1, &ip=null:Int? )->Token[]
      reset
      return tokenize( ip )

    method tokenize( ip=null:Int? )->Token[]
      tokens = Token[]
      if (ip) start_ip = ip.value
      _clear_state
      while (_execute(start_ip) or not halt)
        buffer.clear
      endWhile
      _on_output_line # flush any buffered output
      return tokens

    method _add( type:TokenType )
      if (type.attributes & TokenType.ATTRIBUTE_CONTENT)
        tokens.add( _t(type,buffer.cloned) )
      else
        tokens.add( _t(type) )
      endIf
      buffer.clear

    method _clear_state
      tokens = Token[]
      buffer.clear
      output.clear
      halt = false

    method _describe_character( c:Character )->String
      if (c == 10 or c == 13)       return "end of line";
      elseIf (c >= 32 and c != 127) return "'$'" (c)
      else                          return "'$'" (c.to_escaped_ascii)

    method _discard_position
      if (_position_stack.is_empty)
        _throw_syntax_error( "discardPosition without prior savePosition." )
      endIf
      _position_stack.remove_last
      _line_stack.remove_last
      _column_stack.remove_last
      _token_pos_stack.remove_last

    method _is_next( text:String )->Logical
      local location = _scanner.location
      local result = _scanner.consume( text )
      _scanner.location = location
      return result

    method _must_consume( ch:Character )
      if (_scanner.consume(ch)) return
      local message = "Syntax error - expected $, found " (_describe_character(ch))
      if (_scanner.has_another) message += _describe_character(_scanner.peek) + "."
      else                      message += "end of input."
      throw CompileError( message, _filepath, _scanner.source, _scanner.line, _scanner.column )

    method _must_consume( st:String )
      if (_scanner.consume(st)) return
      _throw_expected_string_error( "'$'" (st.to_escaped_ascii("'")) )

    method _must_consume( pattern:ScanPattern )
      if (pattern.scan(_scanner)) return
      _throw_expected_string_error( pattern->String )

    method _next_is( text:String )->Logical
      if (not _scanner.has_another(text.count)) return false
      local pos = _scanner.position
      forEach (ch at index in text)
        if (ch != _scanner.data[pos+index]) return false
      endForEach
      return true

    method _on_output_line
      # Default behavior: print out 'output' and clear it. Can override this method.
      print( output )
      flush
      output.clear

    method _restore_position
      if (_position_stack.is_empty)
        _throw_syntax_error( "restorePosition without prior savePosition." )
      endIf
      _scanner.position = _position_stack.remove_last
      _scanner.line     = _line_stack.remove_last
      _scanner.column   = _column_stack.remove_last
      tokens.discard_from( _token_pos_stack.remove_last )

    method _save_position
      _position_stack.add( _scanner.position )
      _line_stack.add( _scanner.line )
      _column_stack.add( _scanner.column )
      _token_pos_stack.add( tokens.count )

    method _scan( ch:Character )->Logical
      if (not _scanner.consume(ch)) return false
      buffer.print ch
      return true

    method _scan( text:String )->Logical
      if (not _scanner.consume(text)) return false
      buffer.print text
      return true

    method _t( type:TokenType, content=null:String )->Token
      return Token( type, _filepath, _scanner.source, line, column, position, content )

    method _throw_expected_string_error( st:String )
      local message = "Syntax error - expected $, found " (st)
      if (_scanner.has_another) message += _describe_character(_scanner.peek) + "."
      else                      message += "end of input."
      throw CompileError( message, _filepath, _scanner.source, _scanner.line, _scanner.column )

    method _throw_syntax_error( message=null:String )
      if (not message)
        local builder = String()
        builder.print "Syntax error - unexpected "
        if (not _scanner.has_another)
          builder.println "end of input."
        else
          builder.[ print(_describe_character(_scanner.peek)), print('.') ]
        endIf
        message = builder
      endIf
      throw CompileError( message, _filepath, _scanner.source, _scanner.line, _scanner.column )

    method _execute( ip:Int )->Logical
      which (ip)
        case ip_scan_standard_token: return r_scan_standard_token
        case ip_scan_charset: return r_scan_charset
        case ip_consume_whitespace: return r_consume_whitespace
        case ip_consume_comment: return r_consume_comment
        case ip_scan_optional_plain_id: return r_scan_optional_plain_id
        case ip_scan_tokens_id: return r_scan_tokens_id
        case ip_scan_token_name: return r_scan_token_name
        case ip_scan_token_symbol: return r_scan_token_symbol
        case ip_scan_token_attributes: return r_scan_token_attributes
        case ip_scan_identifier: return r_scan_identifier
        case ip_must_scan_attribute_identifier: return r_must_scan_attribute_identifier
        case ip_scan_integer: return r_scan_integer
        case ip_scan_native_literal: return r_scan_native_literal
        case ip_scan_single_quoted_string: return r_scan_single_quoted_string
        case ip_scan_double_quoted_string: return r_scan_double_quoted_string
        case ip_scan_anycase_string: return r_scan_anycase_string
        case ip_scan_literal_character: return r_scan_literal_character
        others
          halt = true
          return false
      endWhich

    method r_scan_standard_token->Logical
      if ((not _scanner.has_another))
        halt = true
        return false
      endIf
      if (not r_consume_whitespace) return false
      if (not r_consume_comment) return false
      line     = _scanner.line
      column   = _scanner.column
      position = _scanner.position

      if (_scanner.consume('\n'))
        _add( TokenType.EOL )
        return false
      endIf
      if (not r_scan_identifier) return false
      if (not r_scan_native_literal) return false
      if (not r_scan_single_quoted_string) return false
      if (not r_scan_double_quoted_string) return false
      if (not r_scan_anycase_string) return false
      if (not r_scan_charset) return false
      _scan_table_0.reset
      contingent
        block n=1
          while (_scanner.has_another(n))
            if (not _scan_table_0.accept(_scanner.peek(n-1)))
              escapeWhile
            endIf
            ++n
          endWhile
          necessary (_scan_table_0.has_product)
          loop (_scan_table_0.match_count) _scanner.read
        endBlock
        which (_scan_table_0.product)
          case 1
            _add( TokenType.SYMBOL_ARROW )
            return false
          case 2
            _add( TokenType.SYMBOL_ASSIGN )
            return false
          case 3
            _add( TokenType.SYMBOL_AT )
            return false
          case 4
            _add( TokenType.SYMBOL_BACKQUOTE )
            return false
          case 5
            _add( TokenType.SYMBOL_CARET )
            return false
          case 6
            _add( TokenType.SYMBOL_CLOSE_CURLY )
            return false
          case 7
            _add( TokenType.SYMBOL_CLOSE_PAREN )
            return false
          case 8
            _add( TokenType.SYMBOL_CLOSE_SQUARE )
            return false
          case 9
            _add( TokenType.SYMBOL_COLON )
            return false
          case 10
            _add( TokenType.SYMBOL_COMMA )
            return false
          case 11
            _add( TokenType.SYMBOL_DOT_DOT )
            return false
          case 12
            _add( TokenType.SYMBOL_EMPTY_BRACKETS )
            return false
          case 13
            _add( TokenType.SYMBOL_EQ )
            return false
          case 14
            _add( TokenType.SYMBOL_GE )
            return false
          case 15
            _add( TokenType.SYMBOL_GT )
            return false
          case 16
            _add( TokenType.SYMBOL_LE )
            return false
          case 17
            _add( TokenType.SYMBOL_LT )
            return false
          case 18
            _add( TokenType.SYMBOL_NE )
            return false
          case 19
            _add( TokenType.SYMBOL_MINUS )
            return false
          case 20
            _add( TokenType.SYMBOL_MINUS_MINUS )
            return false
          case 21
            _add( TokenType.SYMBOL_OPEN_CURLY )
            return false
          case 22
            _add( TokenType.SYMBOL_OPEN_PAREN )
            return false
          case 23
            _add( TokenType.SYMBOL_OPEN_SQUARE )
            return false
          case 24
            _add( TokenType.SYMBOL_PLUS )
            return false
          case 25
            _add( TokenType.SYMBOL_PLUS_PLUS )
            return false
          case 26
            _add( TokenType.SYMBOL_QUESTION )
            return false
          case 27
            _add( TokenType.SYMBOL_SEMICOLON )
            return false
          case 28
            _add( TokenType.SYMBOL_SINGLE_QUOTE )
            return false
          case 29
            _add( TokenType.SYMBOL_SLASH )
            return false
          case 30
            _add( TokenType.SYMBOL_STAR )
            return false
          others
            necessary (false)
        endWhich
      unsatisfied
        ch = _scanner.peek
        if (_scan_pattern_0.is_next(_scanner))
          if (not r_scan_integer) return false
          _add( TokenType.INTEGER )
          return false
        endIf
      endContingent
      _throw_syntax_error
      return false

    method r_scan_charset->Logical
      if ((not _scanner.consume('[')))
        return true
      endIf
      if (_scanner.consume(']'))
        _add( TokenType.SYMBOL_EMPTY_BRACKETS )
        return false
      endIf
      buffer.print('[')
      while ((_scanner.has_another and (not _scanner.next_is(']'))))
        ch = _scanner.read
        if ((ch=='\\'))
          ch = _scanner.read
          if ((ch=='n'))
            ch = '\n'
          elseIf ((ch=='r'))
            ch = '\r'
          elseIf ((ch=='t'))
            ch = '\t'
          elseIf ((ch==']'))
            ch = ']'
          else
            buffer.print('\\')
          endIf
        endIf
        buffer.print(ch)
      endWhile
      _must_consume( ']' )
      buffer.print(']')
      _add( TokenType.CHARSET )
      return false

    method r_consume_whitespace->Logical
      while ((_scanner.consume(' ') or _scanner.consume('\t')))
      endWhile
      return true

    method r_consume_comment->Logical
      if (_scanner.consume('#'))
        if (_scanner.consume('{'))
          count = 1
          while (_scanner.has_another)
            ch = _scanner.read
            if ((ch=='\n'))
              _add( TokenType.EOL )
            elseIf ((ch=='#'))
              if (_scanner.consume('{'))
                ++count
              endIf
            elseIf ((ch=='}'))
              if (_scanner.consume('#'))
                --count
                if ((count==0))
                  return false
                endIf
              endIf
            endIf
          endWhile
          halt = true
          return false
        else
          while (_scanner.has_another)
            ch = _scanner.read
            if ((ch=='\n'))
              _add( TokenType.EOL )
              return false
            endIf
          endWhile
          return false
        endIf
      elseIf ((_scanner.consume("----") or _scanner.consume("====")))
        while (_scanner.has_another)
          ch = _scanner.read
          if ((ch=='\n'))
            _add( TokenType.EOL )
            return false
          endIf
        endWhile
        return false
      else
        return true
      endIf
      return true

    method r_scan_optional_plain_id->Logical
      if ((not _scan_pattern_1.scan(_scanner,buffer)))
        return true
      endIf
      _add( TokenType.IDENTIFIER )
      return false

    method r_scan_tokens_id->Logical
      if (not r_consume_whitespace) return false
      if (not r_consume_comment) return false
      if ((not _scanner.has_another))
        halt = true
        return false
      endIf
      line     = _scanner.line
      column   = _scanner.column
      position = _scanner.position

      start_ip = ip_scan_token_name
      if (_scanner.consume('\n'))
        _add( TokenType.EOL )
        return false
      endIf
      if (not r_scan_optional_plain_id) return false
      _throw_syntax_error("Identifier expected.")
      return false

    method r_scan_token_name->Logical
      if (not r_consume_whitespace) return false
      if (not r_consume_comment) return false
      if ((not _scanner.has_another))
        halt = true
        return false
      endIf
      line     = _scanner.line
      column   = _scanner.column
      position = _scanner.position

      start_ip = ip_scan_token_symbol
      if (_scan_pattern_1.scan(_scanner,buffer))
        _scan_table_1.reset
        contingent
          necessary (_scan_table_1.accept(forEach in buffer))
          which (_scan_table_1.product)
            case 1
              start_ip = ip_scan_standard_token
              _add( TokenType.KEYWORD_NATIVE_TYPES )
              return false
            case 2
              start_ip = ip_scan_standard_token
              _add( TokenType.KEYWORD_PARSER )
              return false
            case 3
              start_ip = ip_scan_standard_token
              _add( TokenType.KEYWORD_SCANNER )
              return false
            case 4
              start_ip = ip_scan_tokens_id
              _add( TokenType.KEYWORD_TOKENS )
              return false
            others
              necessary (false)
          endWhich
        unsatisfied
          _add( TokenType.IDENTIFIER )
          return false
        endContingent
      endIf
      start_ip = ip_scan_token_name
      if (_scanner.consume('\n'))
        _add( TokenType.EOL )
        return false
      endIf
      _throw_syntax_error("Identifier expected.")
      return false

    method r_scan_token_symbol->Logical
      if (_scanner.consume('('))
        while (((_scanner.has_another and (not _scanner.next_is(')'))) and (not _scanner.next_is('\n'))))
          ch = _scanner.read
          buffer.print(ch)
        endWhile
        _must_consume( ')' )
      else
        if (not r_consume_whitespace) return false
        if (_scanner.next_is('\n'))
          start_ip = ip_scan_token_attributes
          return false
        endIf
        while (((_scanner.has_another and (not _scanner.next_is(' '))) and (not _scanner.next_is('\n'))))
          ch = _scanner.read
          buffer.print(ch)
        endWhile
      endIf
      start_ip = ip_scan_token_attributes
      _add( TokenType.SYMBOL )
      return false

    method r_scan_token_attributes->Logical
      if (not r_consume_whitespace) return false
      if (not r_consume_comment) return false
      if ((not _scanner.has_another))
        halt = true
        return false
      endIf
      _scan_table_2.reset
      contingent
        block n=1
          while (_scanner.has_another(n))
            if (not _scan_table_2.accept(_scanner.peek(n-1)))
              escapeWhile
            endIf
            ++n
          endWhile
          necessary (_scan_table_2.has_product)
          loop (_scan_table_2.match_count) _scanner.read
        endBlock
        which (_scan_table_2.product)
          case 0
            start_ip = ip_scan_token_name
            _add( TokenType.EOL )
            return false
          case 1
            _add( TokenType.SYMBOL_OPEN_SQUARE )
            return false
          case 2
            _add( TokenType.SYMBOL_CLOSE_SQUARE )
            return false
          case 3
            _add( TokenType.SYMBOL_COMMA )
            return false
          others
            necessary (false)
        endWhich
      endContingent
      if (not r_must_scan_attribute_identifier) return false
      return true

    method r_scan_identifier->Logical
      ch = _scanner.peek
      if (_scan_pattern_2.scan(_scanner,buffer))
        _scan_table_3.reset
        contingent
          necessary (_scan_table_3.accept(forEach in buffer))
          which (_scan_table_3.product)
            case 1
              start_ip = ip_scan_standard_token
              _add( TokenType.KEYWORD_NATIVE_TYPES )
              return false
            case 2
              start_ip = ip_scan_standard_token
              _add( TokenType.KEYWORD_PARSER )
              return false
            case 3
              start_ip = ip_scan_standard_token
              _add( TokenType.KEYWORD_SCANNER )
              return false
            case 4
              start_ip = ip_scan_tokens_id
              _add( TokenType.KEYWORD_TOKENS )
              return false
            case 5
              _add( TokenType.KEYWORD_ELSE_OTHERS )
              return false
            case 6
              _add( TokenType.KEYWORD_AND )
              return false
            case 7
              _add( TokenType.KEYWORD_CALL )
              return false
            case 8
              _add( TokenType.KEYWORD_CONSUME )
              return false
            case 9
              _add( TokenType.KEYWORD_CONSUME_ANY )
              return false
            case 10
              _add( TokenType.KEYWORD_CREATE )
              return false
            case 11
              _add( TokenType.KEYWORD_DISCARD_POSITION )
              return false
            case 12
              _add( TokenType.KEYWORD_ELSE )
              return false
            case 13
              _add( TokenType.KEYWORD_ELSE_IF )
              return false
            case 14
              _add( TokenType.KEYWORD_END_IF )
              return false
            case 15
              _add( TokenType.KEYWORD_END_WHILE )
              return false
            case 16
              _add( TokenType.KEYWORD_FALSE )
              return false
            case 17
              _add( TokenType.KEYWORD_HALT )
              return false
            case 18
              _add( TokenType.KEYWORD_HAS_NEXT )
              return false
            case 19
              _add( TokenType.KEYWORD_IF )
              return false
            case 20
              _add( TokenType.KEYWORD_MARK_POSITION )
              return false
            case 21
              _add( TokenType.KEYWORD_MODE )
              return false
            case 22
              _add( TokenType.KEYWORD_MUST_CONSUME )
              return false
            case 23
              _add( TokenType.KEYWORD_NEXT_IS )
              return false
            case 24
              _add( TokenType.KEYWORD_NO_ACTION )
              return false
            case 25
              _add( TokenType.KEYWORD_NOT )
              return false
            case 26
              _add( TokenType.KEYWORD_OR )
              return false
            case 27
              _add( TokenType.KEYWORD_OTHERS )
              return false
            case 28
              _add( TokenType.KEYWORD_PRINT )
              return false
            case 29
              _add( TokenType.KEYWORD_PRINTLN )
              return false
            case 30
              _add( TokenType.KEYWORD_PRODUCE )
              return false
            case 31
              _add( TokenType.KEYWORD_READ )
              return false
            case 32
              _add( TokenType.KEYWORD_RESTORE_POSITION )
              return false
            case 33
              _add( TokenType.KEYWORD_RETURN )
              return false
            case 34
              _add( TokenType.KEYWORD_SAVE_POSITION )
              return false
            case 35
              _add( TokenType.KEYWORD_SCAN )
              return false
            case 36
              _add( TokenType.KEYWORD_SYNTAX_ERROR )
              return false
            case 37
              _add( TokenType.KEYWORD_TRUE )
              return false
            case 38
              _add( TokenType.KEYWORD_WHILE )
              return false
            case 39
              _add( TokenType.KEYWORD_BEGIN_LIST )
              return false
            case 40
              _add( TokenType.KEYWORD_CREATE_LIST )
              return false
            case 41
              _add( TokenType.KEYWORD_CREATE_NULL )
              return false
            case 42
              _add( TokenType.KEYWORD_CREATE_TOKEN_LIST )
              return false
            case 43
              _add( TokenType.KEYWORD_CREATE_TOKEN_LIST_PRESERVING_STACK )
              return false
            case 44
              _add( TokenType.KEYWORD_DISCARD_LIST )
              return false
            case 45
              _add( TokenType.KEYWORD_DUPLICATE )
              return false
            case 46
              _add( TokenType.KEYWORD_ELSE_ON )
              return false
            case 47
              _add( TokenType.KEYWORD_ELSE_ON_PEEK )
              return false
            case 48
              _add( TokenType.KEYWORD_ELSE_OTHERS )
              return false
            case 49
              _add( TokenType.KEYWORD_END_ON )
              return false
            case 50
              _add( TokenType.KEYWORD_NEXT_HAS_ATTRIBUTE )
              return false
            case 51
              _add( TokenType.KEYWORD_ON )
              return false
            case 52
              _add( TokenType.KEYWORD_ON_PEEK )
              return false
            case 53
              _add( TokenType.KEYWORD_POP )
              return false
            case 54
              _add( TokenType.KEYWORD_PRODUCE_LIST )
              return false
            case 55
              _add( TokenType.KEYWORD_PRODUCE_NULL )
              return false
            case 56
              _add( TokenType.KEYWORD_PRODUCE_TOKEN_LIST )
              return false
            case 57
              _add( TokenType.KEYWORD_PRODUCE_TOKEN_LIST_PRESERVING_STACK )
              return false
            case 58
              _add( TokenType.KEYWORD_PUSH )
              return false
            case 59
              _add( TokenType.KEYWORD_BUFFER )
              return false
            case 60
              _add( TokenType.KEYWORD_CASE )
              return false
            case 61
              _add( TokenType.KEYWORD_CHARACTER )
              return false
            case 62
              _add( TokenType.KEYWORD_COLLECT )
              return false
            case 63
              _add( TokenType.KEYWORD_CREATE_ANY )
              return false
            case 64
              _add( TokenType.KEYWORD_END_MATCH )
              return false
            case 65
              _add( TokenType.KEYWORD_INPUT )
              return false
            case 66
              _add( TokenType.KEYWORD_INT )
              return false
            case 67
              _add( TokenType.KEYWORD_INTEGER )
              return false
            case 68
              _add( TokenType.KEYWORD_OUTPUT )
              return false
            case 69
              _add( TokenType.KEYWORD_PEEK )
              return false
            case 70
              _add( TokenType.KEYWORD_PRODUCE_ANY )
              return false
            case 71
              _add( TokenType.KEYWORD_MATCH )
              return false
            case 72
              _add( TokenType.KEYWORD_RESTART )
              return false
            others
              necessary (false)
          endWhich
        unsatisfied
          _add( TokenType.IDENTIFIER )
          return false
        endContingent
      endIf
      return true

    method r_must_scan_attribute_identifier->Logical
      if (_scan_pattern_2.scan(_scanner,buffer))
        _add( TokenType.IDENTIFIER )
        return false
      endIf
      _throw_syntax_error("Identifier expected.")
      return false

    method r_scan_integer->Logical
      while (_scan_pattern_3.is_next(_scanner))
        ch = _scanner.read
        if ((ch!='_'))
          buffer.print(ch)
        endIf
        if ((not _scanner.has_another))
          return true
        endIf
        ch = _scanner.peek
      endWhile
      return true

    method r_scan_native_literal->Logical
      if ((not _scanner.consume('`')))
        return true
      endIf
      while (_scanner.has_another)
        if (_scanner.consume('`'))
          _add( TokenType.NATIVE_LITERAL )
          return false
        endIf
        if (_scanner.next_is('\n'))
          _throw_syntax_error("Unterminated native literal.")
          return false
        endIf
        if (not r_scan_literal_character) return false
      endWhile
      _throw_syntax_error("Unterminated native literal.")
      return false

    method r_scan_single_quoted_string->Logical
      if ((not _scanner.consume('\'')))
        return true
      endIf
      while (_scanner.has_another)
        if (_scanner.consume('\''))
          _add( TokenType.STRING_OR_CHARACTER )
          return false
        endIf
        if (_scanner.next_is('\n'))
          _throw_syntax_error("Unterminated string.")
          return false
        endIf
        if (not r_scan_literal_character) return false
      endWhile
      _throw_syntax_error("Unterminated string.")
      return false

    method r_scan_double_quoted_string->Logical
      if ((not _scanner.consume('"')))
        return true
      endIf
      while (_scanner.has_another)
        if (_scanner.consume('"'))
          _add( TokenType.STRING )
          return false
        endIf
        if (_scanner.next_is('\n'))
          _throw_syntax_error("Unterminated string.")
          return false
        endIf
        if (not r_scan_literal_character) return false
      endWhile
      _throw_syntax_error("Unterminated string.")
      return false

    method r_scan_anycase_string->Logical
      if ((not _scanner.consume("~\"")))
        return true
      endIf
      while (_scanner.has_another)
        if (_scanner.consume('"'))
          _add( TokenType.ANYCASE_STRING )
          return false
        endIf
        if (_scanner.next_is('\n'))
          _throw_syntax_error("Unterminated string.")
          return false
        endIf
        if (not r_scan_literal_character) return false
      endWhile
      _throw_syntax_error("Unterminated string.")
      return false

    method r_scan_literal_character->Logical
      ch = _scanner.read
      if ((ch=='\\'))
        ch = _scanner.read
        if ((ch=='n'))
          ch = '\n'
        endIf
        if ((ch=='r'))
          ch = '\r'
        endIf
        if ((ch=='t'))
          ch = '\t'
        endIf
      endIf
      buffer.print(ch)
      return true

endClass
