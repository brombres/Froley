module F3

# Generated by Froley. WARNING: WILL BE OVERWRITTEN.
class ScannerCore [abstract]
  DEFINITIONS
    ip_scan_standard_token = 0
    ip_scan_charset = 1
    ip_consume_whitespace = 2
    ip_consume_comment = 3
    ip_scan_optional_plain_id = 4
    ip_scan_tokens_id = 5
    ip_scan_token_name = 6
    ip_scan_token_symbol = 7
    ip_scan_token_attributes = 8
    ip_scan_identifier = 9
    ip_must_scan_attribute_identifier = 10
    ip_scan_integer = 11
    ip_scan_single_quoted_string = 12
    ip_scan_double_quoted_string = 13
    ip_scan_literal_character = 14

  PROPERTIES
    _filepath     : String
    _scanner      : ::Scanner
    _src_line     = 1
    _src_column   = 1

    tokens        = Token[]
    buffer        = StringBuilder()
    output        = StringBuilder()

    start_ip      = 0
    ip            : Int32
    halt          = false

    _position_stack = Int32[]

    # GENERATED PROPERTIES
    ch    : Character
    count : Int32
    _scan_pattern_0 = ScanPattern( "[0-9]" )
    _scan_pattern_1 = ScanPattern( "{[a-zA-Z_][a-zA-Z_0-9]*}" )
    _scan_pattern_2 = ScanPattern( "{[a-zA-Z_][a-zA-Z0-9_]*}" )
    _scan_pattern_3 = ScanPattern( "[0-9_]" )
    scan_table_0 = ScanTable("gS4AFy0wPTpAQF5CfUQpRl1IOkosTC5OW1Q+WjxgIWZ7bChuK3A/djt4J3ovgQgqgQp0gQwSAj42LTgBABMAAgE9PgwAAwAEAAUABgAHAAgACQD/AS5SCgAWAV1YCwAOAT1eDQAQAT1kDwD/AT1qEQAUABUAFwErdBgAGQAaAP8BXH7/ASeBAv8BJ4EGGwAcAB0A/wEugRD/AWOBFP8Bb4EY/wFugRz/AXSBIP8BZYEk/wFugSj/AXSBLB4A")
    scan_table_1 = ScanTable("TgADcAhzHnQ4/wFhDP8BchD/AXMU/wFlGP8BchwBAP8BYyL/AWEm/wFuKv8Bbi7/AWUy/wFyNgIA/wFvPP8Ba0D/AWVE/wFuSP8Bc0wDAA==")
    scan_table_2 = ScanTable("Ev8ECgpbDF0OLBAAAAEAAgADAA==")
    scan_table_3 = ScanTable("iFYAEHAic4EQdIF+YYIgY4IqZIMsZYN2ZoRoaIR6aYUobYU+boYsb4cScocwd4gOYogg/wJhKHI6/wFyLP8BczD/AWU0/wFyOAEA/wJpQG9S/wFuRP8BdEgaAWxM/wFuUBsA/wFkVv8BdVr/AWNe/wFlYhwDTGpOeEGBBv8BaW7/AXNy/wF0di4A/wF1fP8BbIEA/wFsgQQvAP8BboEK/wF5gQ41AP8DY4EYYYEueYFY/wFhgRz/AW6BICEBboEk/wFlgSj/AXKBLAIA/wF2gTL/AWWBNv8BUIE6/wFvgT7/AXOBQv8BaYFG/wF0gUr/AWmBTv8Bb4FS/wFugVYgAP8BboFc/wF0gWD/AWGBZP8BeIFo/wFFgWz/AXKBcP8BcoF0/wFvgXj/AXKBfCIA/wJvggRyghb/AWuCCP8BZYIM/wFughD/AXOCFAMA/wF1ghr/AWWCHiMA/wFugiT/AWSCKAQA/wNhgjJvgkRygnr/AmyCOHOCPv8BbII8BQD/AWWCQjEA/wJugkpsgmj/AXOCTv8BdYJS/wFtglb/AWWCWgYBQYJe/wFugmL/AXmCZgcA/wFsgmz/AWWCcP8BY4J0/wF0gngyAP8BZYJ+/wFhgwL/AXSDBv8BZYMKCAJMgxBOgx7/AWmDFP8Bc4MY/wF0gxwmAP8BdYMi/wFsgyb/AWyDKicA/wFpgzD/AXODNP8BY4M4/wFhgzz/AXKDQP8BZINE/wJQg0pMg2j/AW+DTv8Bc4NS/wFpg1b/AXSDWv8BaYNe/wFvg2L/AW6DZgkA/wFpg2z/AXODcP8BdIN0KAD/AmyDfG6EKv8Bc4QA/wFlhAQKAkmECk+EEP8BZoQOCwD/Am6EFnSEGCkA/wFohBz/AWWEIP8BcoQk/wFzhCgqAP8BZIQu/wRJhDhXhD5PhFBNhFb/AWaEPAwA/wFohEL/AWmERv8BbIRK/wFlhE4NAP8BboRUKwD/AWGEWv8BdIRe/wFjhGL/AWiEZjMA/wFhhGz/AWyEcP8Bc4R0/wFlhHgOAP8BYYR+/wJshQRzhQr/AXSFCA8A/wFBhQ7/AW6FEv8Bb4UW/wF0hRr/AWiFHv8BZYUi/wFyhSYQAP8CZoUuboUwEQD/AXCFNP8BdYU4/wF0hTw0AP8DYYVGb4V8dYYG/wJyhUx0hXL/AWuFUP8BUIVU/wFvhVj/AXOFXP8BaYVg/wF0hWT/AWmFaP8Bb4Vs/wFuhXASAP8BY4V2/wFohXo2AP8BZIYA/wFlhgQTAP8Bc4YK/wF0hg7/AUOGEv8Bb4YW/wFuhhr/AXOGHv8BdYYi/wFthib/AWWGKhQA/wJlhjJvhnT/AXiGNv8BdIY6/wJJhkBIhkb/AXOGRBUA/wFhhkr/AXOGTv8BQYZS/wF0hlb/AXSGWv8BcoZe/wFphmL/AWKGZv8BdYZq/wF0hm7/AWWGciwA/wJBhnp0hxD/AWOGfv8BdIcC/wFphwb/AW+HCv8BbocOFgAXAP8DcocadIccbocuGAD/AWiHIP8BZYck/wFyhyj/AXOHLBkALQD/AWWHNP8DYYc8c4dCdIgA/wFkh0AdAP8BdIdG/wJvh0xhh3b/AXKHUP8BZYdU/wFQh1j/AW+HXP8Bc4dg/wFph2T/AXSHaP8BaYds/wFvh3D/AW6HdB4A/wFyh3r/AXSHfjcA/wF1iAT/AXKICP8BbogMHwD/AWiIEv8BaYgW/wFsiBr/AWWIHiQA/wJliCZ1iET/AWeIKv8BaYgu/wFuiDL/AUyINv8BaYg6/wFziD7/AXSIQiUA/wFmiEj/AWaITP8BZYhQ/wFyiFQwAA==")

  METHODS
    method init( file:File )
      init( file.filepath, ::Scanner(file) )

    method init( filepath:String, content:String )
      init( filepath, ::Scanner(content) )

    method init( _filepath, _scanner )
      noAction

    method execute( ip:Int32 )
      _clear_state
      _execute( ip )

    method tokenize( ip=null:Int32? )->Token[]
      if (ip) start_ip = ip.value
      _clear_state
      while (_execute(start_ip) or not halt)
        buffer.clear
      endWhile
      return tokens

    method _add( type:TokenType )
      if (type.attributes & TokenType.ATTRIBUTE_CONTENT)
        tokens.add( _t(type,buffer) )
      else
        tokens.add( _t(type) )
      endIf

    method _clear_state
      tokens = Token[]
      buffer.clear
      output.clear
      _src_line = 1
      _src_column = 1
      halt = false

    method _describe_character( c:Character )->String
      if (c == 10 or c == 13)       return "end of line";
      elseIf (c >= 32 and c != 127) return "'$'" (c)
      else                          return "'$'" (c.to_escaped_ascii)

    method _is_next( text:String )->Logical
      local location = _scanner.location
      local result = _scanner.consume( text )
      _scanner.location = location
      return result

    method _must_consume( ch:Character )
      if (_scanner.consume(ch)) return
      local message = "Syntax error - expected $, found " (_describe_character(ch))
      if (_scanner.has_another) message += _describe_character(_scanner.peek) + "."
      else                      message += "end of input."
      throw SyntaxError( message, _filepath, _scanner.source, _scanner.line, _scanner.column )

    method _must_consume( st:String )
      if (_scanner.consume(st)) return
      _throw_expected_string_error( "'$'" (st.to_escaped_ascii("'")) )

    method _must_consume( pattern:ScanPattern )
      if (pattern.scan(_scanner)) return
      _throw_expected_string_error( pattern->String )

    method _on_output_line
      # Default behavior: print out 'output' and clear it. Can override this method.
      print output
      output.clear

    method _scan( ch:Character )->Logical
      if (not _scanner.consume(ch)) return false
      buffer.print ch
      return true

    method _scan( text:String )->Logical
      if (not _scanner.consume(text)) return false
      buffer.print text
      return true

    method _t( type:TokenType, content=null:String )->Token
      return Token( type, _filepath, _scanner.source, _src_line, _src_column, content )

    method _throw_expected_string_error( st:String )
      local message = "Syntax error - expected $, found " (st)
      if (_scanner.has_another) message += _describe_character(_scanner.peek) + "."
      else                      message += "end of input."
      throw SyntaxError( message, _filepath, _scanner.source, _scanner.line, _scanner.column )

    method _throw_syntax_error( message=null:String )
      if (not message)
        local builder = StringBuilder()
        builder.print "Syntax error - unexpected "
        if (not _scanner.has_another)
          builder.println "end of input."
        else
          builder.print( _describe_character(_scanner.peek) ).print( '.' )
        endIf
        message = builder->String
      endIf
      throw SyntaxError( message, _filepath, _scanner.source, _scanner.line, _scanner.column )

    method _execute( ip:Int32 )->Logical
      loop
        ++ip
        which (ip-1)
          case ip_scan_standard_token
            if ((not _scanner.has_another))
              halt = true
              return false
            endIf
            if (not _execute(ip_consume_whitespace)) return false
            if (not _execute(ip_consume_comment)) return false
            _src_line   = _scanner.line
            _src_column = _scanner.column
            if (_scanner.consume('\n'))

              _add( TokenType.EOL )
              return false
            endIf
            if (not _execute(ip_scan_identifier)) return false
            if (not _execute(ip_scan_single_quoted_string)) return false
            if (not _execute(ip_scan_double_quoted_string)) return false
            if (not _execute(ip_scan_charset)) return false
            scan_table_0.reset
            contingent
              block n=1
                while (_scanner.has_another(n))
                  if (not scan_table_0.accept(_scanner.peek(n-1)))
                    escapeWhile
                  endIf
                  ++n
                endWhile
                necessary (scan_table_0.has_product)
                loop (scan_table_0.match_count) _scanner.read
              endBlock
              which (scan_table_0.product)
                case 1
                  _add( TokenType.SYMBOL_ARROW )
                  return false
                case 2
                  _add( TokenType.SYMBOL_ASSIGN )
                  return false
                case 3
                  _add( TokenType.SYMBOL_AT )
                  return false
                case 4
                  _add( TokenType.SYMBOL_CARET )
                  return false
                case 5
                  _add( TokenType.SYMBOL_CLOSE_CURLY )
                  return false
                case 6
                  _add( TokenType.SYMBOL_CLOSE_PAREN )
                  return false
                case 7
                  _add( TokenType.SYMBOL_CLOSE_SQUARE )
                  return false
                case 8
                  _add( TokenType.SYMBOL_COLON )
                  return false
                case 9
                  _add( TokenType.SYMBOL_COMMA )
                  return false
                case 10
                  _add( TokenType.SYMBOL_DOT_DOT )
                  return false
                case 11
                  _add( TokenType.SYMBOL_EMPTY_BRACKETS )
                  return false
                case 12
                  _add( TokenType.SYMBOL_EQ )
                  return false
                case 13
                  _add( TokenType.SYMBOL_GE )
                  return false
                case 14
                  _add( TokenType.SYMBOL_GT )
                  return false
                case 15
                  _add( TokenType.SYMBOL_LE )
                  return false
                case 16
                  _add( TokenType.SYMBOL_LT )
                  return false
                case 17
                  _add( TokenType.SYMBOL_NE )
                  return false
                case 18
                  _add( TokenType.SYMBOL_MINUS )
                  return false
                case 19
                  _add( TokenType.SYMBOL_MINUS_MINUS )
                  return false
                case 20
                  _add( TokenType.SYMBOL_OPEN_CURLY )
                  return false
                case 21
                  _add( TokenType.SYMBOL_OPEN_PAREN )
                  return false
                case 22
                  _add( TokenType.SYMBOL_OPEN_SQUARE )
                  return false
                case 23
                  _add( TokenType.SYMBOL_PLUS )
                  return false
                case 24
                  _add( TokenType.SYMBOL_PLUS_PLUS )
                  return false
                case 25
                  _add( TokenType.SYMBOL_QUESTION )
                  return false
                case 26
                  _add( TokenType.SYMBOL_SEMICOLON )
                  return false
                case 27
                  _add( TokenType.SYMBOL_SINGLE_QUOTE )
                  return false
                case 28
                  _add( TokenType.SYMBOL_SLASH )
                  return false
                case 29
                  _add( TokenType.SYMBOL_STAR )
                  return false
                case 30
                  _add( TokenType.SYMBOL_T_CONTENT )
                  return false
              endWhich
            unsatisfied
              ch = _scanner.peek 
              if (_scan_pattern_0.is_next(_scanner))
                if (not _execute(ip_scan_integer)) return false

                _add( TokenType.INTEGER )
                return false
              endIf
            endContingent
            _throw_syntax_error
          case ip_scan_charset
            if ((not _scanner.consume('[')))
              return true
            endIf
            if (_scanner.consume(']'))

              _add( TokenType.SYMBOL_EMPTY_BRACKETS )
              return false
            endIf
            buffer.print('[')
            while ((_scanner.has_another and (not _scanner.next_is(']'))))
              ch = _scanner.read
              if ((ch=='\\'))
                ch = _scanner.read
                if ((ch=='n'))
                  ch = '\n'
                elseIf ((ch=='r'))
                  ch = '\r'
                elseIf ((ch=='t'))
                  ch = '\t'
                else
                  buffer.print('\\')
                endIf
              endIf
              buffer.print(ch)
            endWhile
            _must_consume( ']' )
            buffer.print(']')

            _add( TokenType.CHARSET )
            return false
          case ip_consume_whitespace
            while ((_scanner.consume(' ') or _scanner.consume('\t')))
            endWhile
            return true
          case ip_consume_comment
            if (_scanner.consume('#'))
              if (_scanner.consume('{'))
                count = 1
                while (_scanner.has_another)
                  ch = _scanner.read
                  if ((ch=='\n'))

                    _add( TokenType.EOL )

                  elseIf ((ch=='#'))
                    if (_scanner.consume('{'))
                      ++count
                    endIf
                  elseIf ((ch=='}'))
                    if (_scanner.consume('#'))
                      --count
                      if ((count==0))
                        return false
                      endIf
                    endIf
                  endIf
                endWhile
                halt = true
                return false
              else
                while (_scanner.has_another)
                  ch = _scanner.read
                  if ((ch=='\n'))

                    _add( TokenType.EOL )
                    return false
                  endIf
                endWhile
                return false
              endIf
            elseIf ((_scanner.consume("----") or _scanner.consume("====")))
              while (_scanner.has_another)
                ch = _scanner.read
                if ((ch=='\n'))

                  _add( TokenType.EOL )
                  return false
                endIf
              endWhile
              return false
            else
              return true
            endIf
          case ip_scan_optional_plain_id
            if ((not _scan_pattern_1.scan(_scanner,buffer)))
              return true
            endIf

            _add( TokenType.IDENTIFIER )
            return false
          case ip_scan_tokens_id
            if (not _execute(ip_consume_whitespace)) return false
            if (not _execute(ip_consume_comment)) return false
            if ((not _scanner.has_another))
              halt = true
              return false
            endIf
            _src_line   = _scanner.line
            _src_column = _scanner.column
            start_ip = ip_scan_token_name
            if (_scanner.consume('\n'))

              _add( TokenType.EOL )
              return false
            endIf
            if (not _execute(ip_scan_optional_plain_id)) return false
            _throw_syntax_error("1 Identifier expected.")
          case ip_scan_token_name
            if (not _execute(ip_consume_whitespace)) return false
            if (not _execute(ip_consume_comment)) return false
            if ((not _scanner.has_another))
              halt = true
              return false
            endIf
            _src_line   = _scanner.line
            _src_column = _scanner.column
            start_ip = ip_scan_token_symbol
            if (_scan_pattern_1.scan(_scanner,buffer))
              scan_table_1.reset
              contingent
                necessary (scan_table_1.accept(forEach in buffer))
                which (scan_table_1.product)
                  case 1
                    start_ip = ip_scan_standard_token

                    _add( TokenType.KEYWORD_PARSER )
                    return false
                  case 2
                    start_ip = ip_scan_standard_token

                    _add( TokenType.KEYWORD_SCANNER )
                    return false
                  case 3
                    start_ip = ip_scan_tokens_id

                    _add( TokenType.KEYWORD_TOKENS )
                    return false
                endWhich
              unsatisfied

                _add( TokenType.IDENTIFIER )
                return false
              endContingent
            endIf
            start_ip = ip_scan_token_name
            if (_scanner.consume('\n'))

              _add( TokenType.EOL )
              return false
            endIf
            _throw_syntax_error("2 Identifier expected.")
          case ip_scan_token_symbol
            if (_scanner.consume('('))
              while (((_scanner.has_another and (not _scanner.next_is(')'))) and (not _scanner.next_is('\n'))))
                ch = _scanner.read
                buffer.print(ch)
              endWhile
              _must_consume( ')' )
            else
              if (not _execute(ip_consume_whitespace)) return false
              if (_scanner.next_is('\n'))
                start_ip = ip_scan_token_attributes
                return false
              endIf
              while (((_scanner.has_another and (not _scanner.next_is(' '))) and (not _scanner.next_is('\n'))))
                ch = _scanner.read
                buffer.print(ch)
              endWhile
            endIf
            start_ip = ip_scan_token_attributes

            _add( TokenType.SYMBOL )
            return false
          case ip_scan_token_attributes
            if (not _execute(ip_consume_whitespace)) return false
            if (not _execute(ip_consume_comment)) return false
            if ((not _scanner.has_another))
              halt = true
              return false
            endIf
            scan_table_2.reset
            contingent
              block n=1
                while (_scanner.has_another(n))
                  if (not scan_table_2.accept(_scanner.peek(n-1)))
                    escapeWhile
                  endIf
                  ++n
                endWhile
                necessary (scan_table_2.has_product)
                loop (scan_table_2.match_count) _scanner.read
              endBlock
              which (scan_table_2.product)
                case 0
                  start_ip = ip_scan_token_name

                  _add( TokenType.EOL )
                  return false
                case 1

                  _add( TokenType.SYMBOL_OPEN_SQUARE )
                  return false
                case 2

                  _add( TokenType.SYMBOL_CLOSE_SQUARE )
                  return false
                case 3

                  _add( TokenType.SYMBOL_COMMA )
                  return false
              endWhich
            endContingent
            if (not _execute(ip_must_scan_attribute_identifier)) return false
          case ip_scan_identifier
            ch = _scanner.peek 
            if (_scan_pattern_2.scan(_scanner,buffer))
              scan_table_3.reset
              contingent
                necessary (scan_table_3.accept(forEach in buffer))
                which (scan_table_3.product)
                  case 1
                    start_ip = ip_scan_standard_token

                    _add( TokenType.KEYWORD_PARSER )
                    return false
                  case 2
                    start_ip = ip_scan_standard_token

                    _add( TokenType.KEYWORD_SCANNER )
                    return false
                  case 3
                    start_ip = ip_scan_tokens_id

                    _add( TokenType.KEYWORD_TOKENS )
                    return false
                  case 4
                    _add( TokenType.KEYWORD_AND )
                    return false
                  case 5
                    _add( TokenType.KEYWORD_CALL )
                    return false
                  case 6
                    _add( TokenType.KEYWORD_CONSUME )
                    return false
                  case 7
                    _add( TokenType.KEYWORD_CONSUME_ANY )
                    return false
                  case 8
                    _add( TokenType.KEYWORD_CREATE )
                    return false
                  case 9
                    _add( TokenType.KEYWORD_DISCARD_POSITION )
                    return false
                  case 10
                    _add( TokenType.KEYWORD_ELSE )
                    return false
                  case 11
                    _add( TokenType.KEYWORD_ELSE_IF )
                    return false
                  case 12
                    _add( TokenType.KEYWORD_END_IF )
                    return false
                  case 13
                    _add( TokenType.KEYWORD_END_WHILE )
                    return false
                  case 14
                    _add( TokenType.KEYWORD_FALSE )
                    return false
                  case 15
                    _add( TokenType.KEYWORD_HALT )
                    return false
                  case 16
                    _add( TokenType.KEYWORD_HAS_NEXT )
                    return false
                  case 17
                    _add( TokenType.KEYWORD_IF )
                    return false
                  case 18
                    _add( TokenType.KEYWORD_MARK_POSITION )
                    return false
                  case 19
                    _add( TokenType.KEYWORD_MODE )
                    return false
                  case 20
                    _add( TokenType.KEYWORD_MUST_CONSUME )
                    return false
                  case 21
                    _add( TokenType.KEYWORD_NEXT_IS )
                    return false
                  case 22
                    _add( TokenType.KEYWORD_NO_ACTION )
                    return false
                  case 23
                    _add( TokenType.KEYWORD_NOT )
                    return false
                  case 24
                    _add( TokenType.KEYWORD_OR )
                    return false
                  case 25
                    _add( TokenType.KEYWORD_OTHERS )
                    return false
                  case 26
                    _add( TokenType.KEYWORD_PRINT )
                    return false
                  case 27
                    _add( TokenType.KEYWORD_PRINTLN )
                    return false
                  case 28
                    _add( TokenType.KEYWORD_PRODUCE )
                    return false
                  case 29
                    _add( TokenType.KEYWORD_READ )
                    return false
                  case 30
                    _add( TokenType.KEYWORD_RESTORE_POSITION )
                    return false
                  case 31
                    _add( TokenType.KEYWORD_RETURN )
                    return false
                  case 32
                    _add( TokenType.KEYWORD_SAVE_POSITION )
                    return false
                  case 33
                    _add( TokenType.KEYWORD_SCAN )
                    return false
                  case 34
                    _add( TokenType.KEYWORD_SYNTAX_ERROR )
                    return false
                  case 35
                    _add( TokenType.KEYWORD_TRUE )
                    return false
                  case 36
                    _add( TokenType.KEYWORD_WHILE )
                    return false
                  case 37
                    _add( TokenType.KEYWORD_BEGIN_LIST )
                    return false
                  case 38
                    _add( TokenType.KEYWORD_CREATE_LIST )
                    return false
                  case 39
                    _add( TokenType.KEYWORD_CREATE_NULL )
                    return false
                  case 40
                    _add( TokenType.KEYWORD_DISCARD_LIST )
                    return false
                  case 41
                    _add( TokenType.KEYWORD_ELSE_ON )
                    return false
                  case 42
                    _add( TokenType.KEYWORD_ELSE_OTHERS )
                    return false
                  case 43
                    _add( TokenType.KEYWORD_END_ON )
                    return false
                  case 44
                    _add( TokenType.KEYWORD_NEXT_HAS_ATTRIBUTE )
                    return false
                  case 45
                    _add( TokenType.KEYWORD_ON )
                    return false
                  case 46
                    _add( TokenType.KEYWORD_PRODUCE_LIST )
                    return false
                  case 47
                    _add( TokenType.KEYWORD_PRODUCE_NULL )
                    return false
                  case 48
                    _add( TokenType.KEYWORD_BUFFER )
                    return false
                  case 49
                    _add( TokenType.KEYWORD_CASE )
                    return false
                  case 50
                    _add( TokenType.KEYWORD_COLLECT )
                    return false
                  case 51
                    _add( TokenType.KEYWORD_END_MATCH )
                    return false
                  case 52
                    _add( TokenType.KEYWORD_INPUT )
                    return false
                  case 53
                    _add( TokenType.KEYWORD_PRODUCE_ANY )
                    return false
                  case 54
                    _add( TokenType.KEYWORD_MATCH )
                    return false
                  case 55
                    _add( TokenType.KEYWORD_RESTART )
                    return false
                endWhich
              unsatisfied

                _add( TokenType.IDENTIFIER )
                return false
              endContingent
            endIf
            return true
          case ip_must_scan_attribute_identifier
            if (_scan_pattern_2.scan(_scanner,buffer))

              _add( TokenType.IDENTIFIER )
              return false
            endIf
            _throw_syntax_error("Identifier expected.")
          case ip_scan_integer
            while (_scan_pattern_3.is_next(_scanner))
              ch = _scanner.read
              if ((ch!='_'))
                buffer.print(ch)
              endIf
              if ((not _scanner.has_another))
                return true
              endIf
              ch = _scanner.peek 
            endWhile
            return true
          case ip_scan_single_quoted_string
            if ((not _scanner.consume('\'')))
              return true
            endIf
            while (_scanner.has_another)
              if (_scanner.consume('\''))

                _add( TokenType.STRING_OR_CHARACTER )
                return false
              endIf
              if (_scanner.next_is('\n'))
                _throw_syntax_error("Unterminated string.")
              endIf
              if (not _execute(ip_scan_literal_character)) return false
            endWhile
            _throw_syntax_error("Unterminated string.")
          case ip_scan_double_quoted_string
            if ((not _scanner.consume('"')))
              return true
            endIf
            while (_scanner.has_another)
              if (_scanner.consume('"'))

                _add( TokenType.STRING )
                return false
              endIf
              if (_scanner.next_is('\n'))
                _throw_syntax_error("Unterminated string.")
              endIf
              if (not _execute(ip_scan_literal_character)) return false
            endWhile
            _throw_syntax_error("Unterminated string.")
          case ip_scan_literal_character
            ch = _scanner.read
            if ((ch=='\\'))
              ch = _scanner.read
              if ((ch=='n'))
                ch = '\n'
              endIf
              if ((ch=='r'))
                ch = '\r'
              endIf
              if ((ch=='t'))
                ch = '\t'
              endIf
            endIf
            buffer.print(ch)
            return true
          others
            halt = true
            return false
        endWhich
      endLoop

endClass
